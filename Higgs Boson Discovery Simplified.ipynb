{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110106c1",
   "metadata": {},
   "source": [
    "# Simplified Introduction To The Standard Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50796c8",
   "metadata": {},
   "source": [
    "## Limitations of \"Seeing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7eb46",
   "metadata": {},
   "source": [
    "### The Physical Act of Seeing: \n",
    "At its most basic, \"seeing\" is the application of light photons hitting the retinal cells in our eyes. As there is physical contact between particles (photons) and biological material (retinal cells) during this interaction, it might be said to be \"touching.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6313c64",
   "metadata": {},
   "source": [
    "### Resolution Limits:\n",
    "The clarity with which we see is dictated by the wavelength of light and the biology of our eyes. At smaller scales (e.g., molecules, atoms, subatomic particles), traditional \"seeing\" is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa857ba",
   "metadata": {},
   "source": [
    "## The Heisenberg Uncertainty Principle and the discovery of Higgs Boson\n",
    "The Heisenberg Uncertainty Principle, a cornerstone in the foundation of quantum mechanics, eloquently captures this limitation. It states that it is inherently impossible to simultaneously know certain pairs of complementary properties of a particle, like its position and momentum, with arbitrary accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fd450",
   "metadata": {},
   "source": [
    "But how does this limit shape our understanding of the fundamental building blocks of the universe? One intriguing case is the discovery of the Higgs boson, a particle that helps explain why other particles have mass. This elusive particle is never \"seen\" directly; instead, its existence is inferred through the scattering and decay of other particles in high-energy environments, such as those created in the Large Hadron Collider at CERN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2595fa2",
   "metadata": {},
   "source": [
    "## Interaction between the Particles, The cosmic game of tag! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b33dc1",
   "metadata": {},
   "source": [
    "Alright, imagine you're playing a game of tag, okay? Normally, you can tag your friends with your hand, just like how most particles interact with each other using something called a photon. A photon is like an invisible hand that lets particles touch each other from a distance. You can think of it like a magical thread that connects two magnets or electric charges, even if they are far apart!\n",
    "\n",
    "Now, there's a special kind of player in this game: the neutrino. Think of neutrinos as super-shy kids that don't like to be tagged easily. They're so sneaky that they don't even get tagged by the usual invisible hand (the photon). Why? Because they're not carrying any electric \"flags\" on them; they have no electric charge. They're like ninjas, really hard to catch!\n",
    "\n",
    "So, how do these shy neutrinos play the game of tag? That's where the \n",
    "Z boson comes in. The Z boson is like a special glove that only these shy kids can feel. When neutrinos want to tag each other, they use this Z glove, which is a special way just for them.\n",
    "\n",
    "You know what's cool? The Z glove is like a cousin to the photon! Just like the photon helps other particles to interact, the Z boson helps neutrinos touch each other in their sneaky game of tag. But unlike the photon, the \n",
    "Z glove is heavy, so it can't throw itself far. That's why neutrinos only use it when they're really, really close to each other.\n",
    "\n",
    "So, in short, the Z boson is a special way for these shy neutrinos to play tag with each other! Without the Z boson, they wouldn't be able to play the game at all! Cool, huh?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bd9cf",
   "metadata": {},
   "source": [
    "## The Unification of the electromagnetic and weak forces?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573ec60",
   "metadata": {},
   "source": [
    "so remember the game of tag with the special Z glove for the shy neutrinos? Well, let's take that game to the next level, like turning on \"hard mode\" in a video game! Imagine you have a super-duper bouncy trampoline. When you jump super high on the trampoline (which is like having lots of energy), you can actually make a Z boson, the special glove, appear for a short moment! And guess what? This Z boson can break apart into different things. It can turn into a pair of super-fast kids like electrons and their anti-twins, or muons and their anti-twins. It can also become those shy neutrinos and their opposite, anti-neutrinos.\n",
    "\n",
    "Now, here's the magical part. You know how superheroes sometimes join forces to become even more powerful? Well, when you jump high enough on the trampoline, the Z boson and the photon—the invisible hand—kind of become friends and mix together. They get so close that they're almost like the same thing for a moment. This is what scientists mean when they talk about the \"unification\" of forces.\n",
    "\n",
    "But here's the twist: if the Z boson wasn't heavy (like how we know it is), then its friend the photon would also become heavy! And if the photon gets heavy, it can't travel very far. You know what that means? Light itself wouldn't be able to go as far as it wants. It's like if you tried to throw a heavy ball; it wouldn't go very far, right? So, no far-reaching light means it would be really dark everywhere!\n",
    "\n",
    "So next time you turn on a light or look at the sun, you can think about how cool it is that the Z boson and photon work the way they do. They make sure our world is bright and full of all kinds of particles playing tag in their own special ways! Isn't science awesome?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2f092",
   "metadata": {},
   "source": [
    "# The Higgs boson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1988313",
   "metadata": {},
   "source": [
    "### the grand finale of our cosmic game of tag! \n",
    "Do you remember the special Z glove that lets shy neutrinos play? Well, guess what, there's an even more magical player in this game, the Higgs boson!\n",
    "\n",
    "Imagine that the Higgs boson is like the wizard of our particle playground. For a long time, scientists had been looking for this wizard because they knew he had super-special powers. The wizard has a magical staff that helps decide how heavy or light all the other players in the game are. You know, like giving them a backpack with either heavy rocks or feathers!\n",
    "\n",
    "In 2012, scientists finally found this wizard! They used a giant machine called a particle accelerator, which is like a super-charged, cosmic merry-go-round. When they spun particles around really, really fast and smashed them together, poof! Out came the Higgs boson wizard, and they knew it was him because he weighed about 125 \"magic beans\" (or, in science words, 125 GeV).\n",
    "\n",
    "Now, the funny thing is, even though the Higgs boson is super important, nobody knew how many magic beans he should weigh. But once scientists found him, they could watch how he used his magic. For example, sometimes he would turn into other particles like a pair of fast kids (those are electrons and their anti-twins) or even the shy neutrinos we talked about!\n",
    "\n",
    "So, by watching the Higgs wizard and his magic tricks, scientists could learn even more about how the game of cosmic tag works. And guess what, all this stuff is happening right now, all around us, even though we can't see it!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9452ff0",
   "metadata": {},
   "source": [
    "# Higgs Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483bc95",
   "metadata": {},
   "source": [
    "The analysis example implements a simplified selection criteria for single Higgs boson events decaying to a couple of photons:\n",
    "\n",
    "Diphoton Trigger: First, we will use a \"magic detector\" that only rings when there are exactly two beams of light (photons) that could come from a Higgs Boson Particle. It's like having a metal detector that beeps only when it's over gold!\n",
    "\n",
    "Checking the Energy: Then, we check if the two beams of light are really bright and powerful. This is because a Higgs Boson Particle's light should be super bright. In science talk, they want one light beam to have more than 35 GeV and the other to have more than 25.\n",
    "\n",
    "More Conditions: We also look at some complicated rules about how these beams of light relate to the whole Higgs Boson Particle. This helps them make sure they're not looking at ordinary particles.\n",
    "\n",
    "The Right Weight of the particle: We want to find a Higgs Boson Particle that weighs between 105 and 160 GeV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a026ded",
   "metadata": {},
   "source": [
    "(I will be using the data provided by ATLAS and CERN for this experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aba522",
   "metadata": {},
   "source": [
    "# The Experiment\n",
    "Alright, science adventurers, gather around! We're going on a treasure hunt, but this time we're hunting for a super special type of golden apple, which scientists call the Higgs boson. And guess what? This special apple turns into not one but TWO Z gloves (Z bosons) that then turn into FOUR super-fast kids (those are called leptons)!\n",
    "\n",
    "So let's talk about our treasure map. Our map has lots of \"X\" marks on it, but not all of them are the special golden apple we're looking for. Some are just regular apples or even rocks, and we want to get rid of those.\n",
    "\n",
    "Getting Rid of $Z$ and $t\\bar{t}$: The first step is to use our magic detector to get rid of anything that's super different from our special apple. These are like the rocks and fake apples in our treasure hunt. In science terms, these are called $Z$ and $t\\bar{t}$ background. We really want to focus on our golden apple!\n",
    "\n",
    "Focusing on \n",
    "$H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$: The next step is to get rid of other special apples that are similar but not exactly what we're looking for. These are like apples that turn into TWO Z gloves but not into FOUR super-fast kids. So we keep adjusting our magic detector to zero in on our special golden apple.\n",
    "\n",
    "Our magic detector already knows to look for events where there are four super-fast kids running around. This makes our treasure hunt go faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341eada",
   "metadata": {},
   "source": [
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker.\n",
    "\n",
    "This analysis loosely follows the [discovery of the Higgs boson by ATLAS](https://www.sciencedirect.com/science/article/pii/S037026931200857X) (mostly Section 4 and 4.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13adad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3 \n",
    "import pandas as pd \n",
    "import time\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import AutoMinorLocator \n",
    "\n",
    "import infofile # local file containing cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74f556",
   "metadata": {},
   "source": [
    "## Lumi, fraction, file path\n",
    "\n",
    "General definitions of fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cedaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 0.1 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff35b9",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9017b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D'],\n",
    "    },\n",
    "\n",
    "    r'Background $Z,t\\bar{t}$' : { # Z + ttbar\n",
    "        'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "        'color' : \"#6b59d3\" # purple\n",
    "    },\n",
    "\n",
    "    r'Background $ZZ^*$' : { # ZZ\n",
    "        'list' : ['llll'],\n",
    "        'color' : \"#ff0000\" # red\n",
    "    },\n",
    "\n",
    "    r'Signal ($m_H$ = 125 GeV)' : { # H -> ZZ -> llll\n",
    "        'list' : ['ggH125_ZZ4lep','VBFH125_ZZ4lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
    "        'color' : \"#00cdff\" # light blue\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f54de",
   "metadata": {},
   "source": [
    "Define function to get data from files.\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28799020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {} # define empty dictionary to hold dataframes\n",
    "    for s in samples: # loop over samples\n",
    "        print('Processing '+s+' samples') # print which sample\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".4lep.root\" # file name to open\n",
    "            temp = read_file(fileString,val) # call the function read_file defined below\n",
    "            frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "        data[s] = pd.concat(frames) # dictionary entry is concatenated dataframes\n",
    "    \n",
    "    return data # return dictionary of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ccdc3",
   "metadata": {},
   "source": [
    "The function multiplies all these factors together to produce a single weight for the MC event. This weight is then typically used to scale the simulated MC event when comparing it to real data or when making histograms. The goal is to ensure the simulated data matches as closely as possible to the conditions and results of the real experiment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d2c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, mcWeight, scaleFactor_PILEUP,\n",
    "                scaleFactor_ELE, scaleFactor_MUON, \n",
    "                scaleFactor_LepTRIGGER ):\n",
    "    return xsec_weight*mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff7387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82487013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mllll(lep_pt,lep_eta,lep_phi,lep_E):\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    px_0 = lep_pt[0]*math.cos(lep_phi[0]) # x-component of lep[0] momentum\n",
    "    py_0 = lep_pt[0]*math.sin(lep_phi[0]) # y-component of lep[0] momentum\n",
    "    pz_0 = lep_pt[0]*math.sinh(lep_eta[0]) # z-component of lep[0] momentum\n",
    "    px_1 = lep_pt[1]*math.cos(lep_phi[1]) # x-component of lep[1] momentum\n",
    "    py_1 = lep_pt[1]*math.sin(lep_phi[1]) # y-component of lep[1] momentum\n",
    "    pz_1 = lep_pt[1]*math.sinh(lep_eta[1]) # z-component of lep[1] momentum\n",
    "    px_2 = lep_pt[2]*math.cos(lep_phi[2]) # x-component of lep[2] momentum\n",
    "    py_2 = lep_pt[2]*math.sin(lep_phi[2]) # y-component of lep[2] momentum\n",
    "    pz_2 = lep_pt[2]*math.sinh(lep_eta[2]) # z-component of lep[3] momentum\n",
    "    px_3 = lep_pt[3]*math.cos(lep_phi[3]) # x-component of lep[3] momentum\n",
    "    py_3 = lep_pt[3]*math.sin(lep_phi[3]) # y-component of lep[3] momentum\n",
    "    pz_3 = lep_pt[3]*math.sinh(lep_eta[3]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3 # x-component of 4-lepton momentum\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3 # y-component of 4-lepton momentum\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3 # z-component of 4-lepton momentum\n",
    "    sumE = lep_E[0] + lep_E[1] + lep_E[2] + lep_E[3] # energy of 4-lepton system\n",
    "    return math.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505117f7",
   "metadata": {},
   "source": [
    " $m = \\sqrt{E^2 - |\\vec{p}|^2} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a21605e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on lepton charge\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton is [0], 2nd lepton is [1] etc\n",
    "    return lep_charge[0] + lep_charge[1] + lep_charge[2] + lep_charge[3] != 0\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumu\n",
    "    sum_lep_type = lep_type[0] + lep_type[1] + lep_type[2] + lep_type[3]\n",
    "    return (sum_lep_type != 44) and (sum_lep_type != 48) and (sum_lep_type != 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feac38f",
   "metadata": {},
   "source": [
    "# Applying the cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d2253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    \n",
    "    try:\n",
    "        tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
    "    except:\n",
    "        print(\"Failed to open tree.\")\n",
    "        return data_all\n",
    "    \n",
    "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
    "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
    "\n",
    "    try:\n",
    "        for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
    "                                  'lep_E','lep_charge','lep_type', \n",
    "                                  'mcWeight','scaleFactor_PILEUP',\n",
    "                                  'scaleFactor_ELE','scaleFactor_MUON',\n",
    "                                  'scaleFactor_LepTRIGGER'],\n",
    "                                 outputtype=pd.DataFrame,\n",
    "                                 entrystop=numevents*fraction):\n",
    "\n",
    "            nIn = len(data.index) # number of events in this batch\n",
    "\n",
    "            if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "                # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "                data['totalWeight'] = np.vectorize(calc_weight)(xsec_weight,\n",
    "                                                                data.mcWeight,\n",
    "                                                                data.scaleFactor_PILEUP,\n",
    "                                                                data.scaleFactor_ELE,\n",
    "                                                                data.scaleFactor_MUON,\n",
    "                                                                data.scaleFactor_LepTRIGGER)\n",
    "\n",
    "            # cut on lepton charge using the function cut_lep_charge defined above\n",
    "            fail = data[ np.vectorize(cut_lep_charge)(data.lep_charge) ].index\n",
    "            data.drop(fail, inplace=True)\n",
    "\n",
    "            # cut on lepton type using the function cut_lep_type defined above\n",
    "            fail = data[ np.vectorize(cut_lep_type)(data.lep_type) ].index\n",
    "            data.drop(fail, inplace=True)\n",
    "\n",
    "            # calculation of 4-lepton invariant mass using the function calc_mllll defined above\n",
    "            data['mllll'] = np.vectorize(calc_mllll)(data.lep_pt,data.lep_eta,data.lep_phi,data.lep_E)\n",
    "\n",
    "            # dataframe contents can be printed at any stage like this\n",
    "            #print(data)\n",
    "\n",
    "            # dataframe column can be printed at any stage like this\n",
    "            #print(data['lep_pt'])\n",
    "\n",
    "            # multiple dataframe columns can be printed at any stage like this\n",
    "            #print(data[['lep_pt','lep_eta']])\n",
    "\n",
    "            nOut = len(data.index) # number of events passing cuts in this batch\n",
    "            print(type(data))\n",
    "\n",
    "            data_all = pd.concat([data_all,data]) # append dataframe from this batch to the dataframe for the whole sample\n",
    "            elapsed = time.time() - start # time taken to process\n",
    "            print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "\n",
    "    except IndexError as e:\n",
    "        print(f\"Encountered an IndexError: {e}\")\n",
    "        print(\"Breaking the loop.\")\n",
    "        return data_all\n",
    "    except Exception as e:\n",
    "        print(f\"Encountered an error: {e}\")\n",
    "        return data_all\n",
    "\n",
    "    return data_all  # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data samples\n",
      "\tProcessing: data_A\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 3,\t nOut: \t2\t in 3.9s\n",
      "\tProcessing: data_B\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 15,\t nOut: \t8\t in 3.0s\n",
      "\tProcessing: data_C\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 23,\t nOut: \t13\t in 3.1s\n",
      "\tProcessing: data_D\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 40,\t nOut: \t20\t in 5.5s\n",
      "Processing Background $Z,t\\bar{t}$ samples\n",
      "\tProcessing: Zee\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 89,\t nOut: \t20\t in 10.3s\n",
      "\tProcessing: Zmumu\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 68,\t nOut: \t28\t in 8.0s\n",
      "\tProcessing: ttbar_lep\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\t\t nIn: 103,\t nOut: \t30\t in 12.1s\n",
      "Processing Background $ZZ^*$ samples\n",
      "\tProcessing: llll\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b34bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    xmin = 80 # GeV\n",
    "    xmax = 250 # GeV\n",
    "    step_size = 5 # GeV\n",
    "\n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(data['data']['mllll'], \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    signal_x = data[r'Signal ($m_H$ = 125 GeV)']['mllll'] # histogram the signal\n",
    "    signal_weights = data[r'Signal ($m_H$ = 125 GeV)'].totalWeight # get the weights of the signal events\n",
    "    signal_color = samples[r'Signal ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
    "\n",
    "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "\n",
    "    for s in samples: # loop over samples\n",
    "        if s not in ['data', r'Signal ($m_H$ = 125 GeV)']: # if not data nor signal\n",
    "            mc_x.append( data[s]['mllll'] ) # append to the list of Monte Carlo histogram entries\n",
    "            mc_weights.append( data[s].totalWeight ) # append to the list of Monte Carlo weights\n",
    "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "    \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
    "                       label='Data') \n",
    "    \n",
    "    # plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
    "                                weights=mc_weights, stacked=True, \n",
    "                                color=mc_colors, label=mc_labels )\n",
    "    \n",
    "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
    "    mc_x_err = np.sqrt( mc_x_tot ) # statistical error on the MC bars\n",
    "    \n",
    "    # plot the signal bar\n",
    "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
    "                   weights=signal_weights, color=signal_color,\n",
    "                   label=r'Signal ($m_H$ = 125 GeV)')\n",
    "    \n",
    "    # plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, # x\n",
    "                  2*mc_x_err, # heights\n",
    "                  alpha=0.5, # half transparency\n",
    "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
    "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # x-axis label\n",
    "    main_axes.set_xlabel(r'4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]',\n",
    "                        fontsize=13, x=1, horizontalalignment='right' )\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
    "                         y=1, horizontalalignment='right') \n",
    "    \n",
    "    # set y-axis limits for main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
    "    \n",
    "    # add minor ticks on y-axis for main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.93, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.88, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.05, # x\n",
    "             0.82, # y\n",
    "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.05, # x\n",
    "             0.76, # y\n",
    "             r'$H \\rightarrow ZZ^* \\rightarrow 4\\ell$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend( frameon=False ) # no box around the legend\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1041536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
